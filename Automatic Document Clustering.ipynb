{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Marco/Documents/CSC 478/data/newsgroups5\n"
     ]
    }
   ],
   "source": [
    "cd /Users/Marco/Documents/CSC 478/data/newsgroups5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import kMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a \n",
    "** Cosine Similarity Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import*\n",
    " \n",
    "def square_rooted(x):\n",
    "    return sqrt(sum([a*a for a in x]))\n",
    " \n",
    "def cosine_similarity(x,y):\n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = square_rooted(x)*square_rooted(y)\n",
    "    return 1-numerator/float(denominator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b \n",
    "**Loading and Preprocessing** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TD = np.loadtxt(open('matrix.txt'),delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9328, 2500)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the indexes of all the rows that have low DF values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NRows= TD.shape[0]\n",
    "list = []\n",
    "for i in range(NRows-1):\n",
    "    if (np.count_nonzero(TD[i]))<10:\n",
    "       list.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the rows with the respective indexes mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TD=np.delete(TD,list,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3368, 2500)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transposing the data into a doc-term matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt = TD.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = np.arange(dt.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the training(80%) and test(20%) data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train,test,idx1,idx2 = train_test_split(dt,indices, test_size = 0.2, random_state = 33) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. c\n",
    "**TFxIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3,edgeitems=4,suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numTerms = len(train[0])\n",
    "NDocs = len(train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF = np.array([(train.T!=0).sum(1)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DF = DF +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NDocs_train = len(train[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NMatrix_train = np.ones(np.shape(train.T),dtype=float)*NDocs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IDF = np.log2(np.divide(NMatrix_train,DF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the IDF I can use it to obtain the TFxIDF for the train and test matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_train= (train.T*IDF).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf_test = (test*IDF[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.d\n",
    "**kMeans Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kMeans' from 'kMeans.pyc'>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(kMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "centroids, clusters = kMeans.kMeans(tfidf_train, 5, kMeans.cos_dist, kMeans.randCent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing the error column since I won't be needing it for this problem\n",
    "clusters=np.delete(clusters,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Adding in the doc index as a column to use as a means of IDing\n",
    "x = np.array([np.concatenate((v,[i])) for i,v in enumerate(clusters)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chuncks of code are my attempt to group the docs into tangible clusters of docs eg. separate the docs into lists depending on what cluster they're in. In order to do this I convert the numpy array into a Pandas Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [\"clusterID\",\"docID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=x,columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('clusterID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c0=grouped.get_group(0)\n",
    "c1=grouped.get_group(1)\n",
    "c2=grouped.get_group(2)\n",
    "c3=grouped.get_group(3)\n",
    "c4=grouped.get_group(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Marco/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/Marco/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Marco/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/Marco/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Marco/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#I don't need the clusterID anymore as it's redudant\n",
    "c0.drop('clusterID', axis=1, inplace=True)\n",
    "c1.drop('clusterID', axis=1, inplace=True)\n",
    "c2.drop('clusterID', axis=1, inplace=True)\n",
    "c3.drop('clusterID', axis=1, inplace=True)\n",
    "c4.drop('clusterID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once I'm done grouping, I convert the \"clusters\" back into (1-D) numpy arrays..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c0=(c0.values).flatten()\n",
    "c1=(c1.values).flatten()\n",
    "c2=(c2.values).flatten()\n",
    "c3=(c3.values).flatten()\n",
    "c4=(c4.values).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert values to int as I will be using them to index \n",
    "c0=c0.astype(int)\n",
    "c1=c1.astype(int)\n",
    "c2=c2.astype(int)\n",
    "c3=c3.astype(int)\n",
    "c4=c4.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docCl=[]\n",
    "docCl.append(c0)\n",
    "docCl.append(c1)\n",
    "docCl.append(c2)\n",
    "docCl.append(c3)\n",
    "docCl.append(c4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I now have an organized version of the original clusters array. docCl is a collection (narrays) of clusters (narray) that each have their respective documents (indexes) in them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docCl=np.array(docCl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The words from the text file\n",
    "terms=np.genfromtxt('terms.txt',dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_info(clusters,centroids,docTerm,terms,N=10):\n",
    "    \n",
    "    #Collecting index of topN terms in centroid\n",
    "    #for each centroid.\n",
    "    terms_in_centroid=[] \n",
    "    for c in centroids:\n",
    "        index_of_terms=heapq.nlargest(N,range(len(c)),c.take)\n",
    "        terms_in_centroid.append(index_of_terms)\n",
    "    \n",
    "    #Computing the DF for each cluster \n",
    "    DFList=[]\n",
    "    for c in clusters:\n",
    "        temp=docTerm[[c]]\n",
    "        DF = np.array([(temp.T!=0).sum(1)])\n",
    "        DFList.append(DF.flatten())\n",
    "    \n",
    "    #Display\n",
    "    for i,c in enumerate(terms_in_centroid):\n",
    "        sizeOfCluster = len(clusters[i])\n",
    "        print \"Cluster: %d Size: %d\"%(i,sizeOfCluster)\n",
    "        for term in c:\n",
    "            DF = DFList[i][int(term)]\n",
    "            word = terms[int(term)]\n",
    "            percent = int((DF/float(sizeOfCluster))*100)\n",
    "            print \"Term: %s\\t Cluster DF:%d\\t Percent: %d\"%(word,DF,percent)\n",
    "        print\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0 Size: 9\n",
      "Term: altath\t Cluster DF:8\t Percent: 88\n",
      "Term: csugradcsvtedu\t Cluster DF:7\t Percent: 77\n",
      "Term: diskman\t Cluster DF:7\t Percent: 77\n",
      "Term: glacial\t Cluster DF:6\t Percent: 66\n",
      "Term: dsuvaxdsuedu\t Cluster DF:6\t Percent: 66\n",
      "\n",
      "Cluster: 1 Size: 165\n",
      "Term: chevi\t Cluster DF:97\t Percent: 58\n",
      "Term: closest\t Cluster DF:36\t Percent: 21\n",
      "Term: exit\t Cluster DF:64\t Percent: 38\n",
      "Term: connector\t Cluster DF:66\t Percent: 40\n",
      "Term: dinari\t Cluster DF:52\t Percent: 31\n",
      "\n",
      "Cluster: 2 Size: 804\n",
      "Term: gizbj\t Cluster DF:297\t Percent: 36\n",
      "Term: carri\t Cluster DF:160\t Percent: 19\n",
      "Term: bottom\t Cluster DF:159\t Percent: 19\n",
      "Term: engumdedu\t Cluster DF:229\t Percent: 28\n",
      "Term: branch\t Cluster DF:83\t Percent: 10\n",
      "\n",
      "Cluster: 3 Size: 233\n",
      "Term: chevi\t Cluster DF:117\t Percent: 50\n",
      "Term: australian\t Cluster DF:105\t Percent: 45\n",
      "Term: author\t Cluster DF:64\t Percent: 27\n",
      "Term: cach\t Cluster DF:48\t Percent: 20\n",
      "Term: clean\t Cluster DF:29\t Percent: 12\n",
      "\n",
      "Cluster: 4 Size: 789\n",
      "Term: biggest\t Cluster DF:3\t Percent: 0\n",
      "Term: content\t Cluster DF:198\t Percent: 25\n",
      "Term: champ\t Cluster DF:216\t Percent: 27\n",
      "Term: floor\t Cluster DF:197\t Percent: 24\n",
      "Term: buddenberg\t Cluster DF:181\t Percent: 22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_info(docCl,centroids,train,terms,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e. \n",
    "**Completeness and Homogeneity** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = clusters[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual = np.loadtxt(open('classes.txt'),skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual = actual[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict = predict.astype(int)\n",
    "actual  = actual.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actual = [actual[i] for i in idx1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719354899289\n"
     ]
    }
   ],
   "source": [
    "print completeness_score(actual,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.542625793855\n"
     ]
    }
   ],
   "source": [
    "print homogeneity_score(actual,predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.f\n",
    "**Testing the training model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_clusters=[]\n",
    "for d in tfidf_test:\n",
    "    dist = []\n",
    "    for c in centroids:\n",
    "        dist.append(spatial.distance.cosine(d,c))\n",
    "    doc = (dist.index(min(dist)),dist)\n",
    "    test_clusters.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(\"part2f.txt\", \"w\")\n",
    "for doc in test_clusters:\n",
    "    file.write(\"%s%s\\n\" % doc)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
